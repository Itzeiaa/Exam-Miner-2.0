<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>WebLLM Demo (JS-only LLM)</title>
<style>
  body{font-family:system-ui,Segoe UI,Arial,sans-serif;margin:24px;max-width:820px}
  h1{font-size:20px;margin:0 0 12px}
  .row{display:flex;gap:10px;align-items:center;flex-wrap:wrap}
  select,button,textarea{font:inherit}
  textarea{width:100%;min-height:160px;padding:10px;border:1px solid #ccd;border-radius:8px}
  button{padding:10px 14px;border:1px solid #3b82f6;background:#3b82f6;color:#fff;border-radius:8px;cursor:pointer}
  button:disabled{opacity:.6;cursor:not-allowed}
  .out{white-space:pre-wrap;border:1px solid #eee;background:#fafafa;padding:12px;border-radius:8px;min-height:120px}
  .progress{height:8px;background:#eef2ff;border-radius:6px;overflow:hidden;margin:8px 0 2px}
  .bar{height:100%;width:0;background:#60a5fa;transition:width .2s}
  small.mono{font-family:ui-monospace,Menlo,Consolas,monospace;color:#666}
</style>
</head>
<body>
  <h1>WebLLM Demo (runs fully in your browser)</h1>

  <div class="row">
    <label for="model">Model:</label>
    <select id="model">
      <option value="Llama-3.2-3B-Instruct-q4f16_1-MLC">Llama 3.2 3B Instruct (Q4)</option>
      <!-- You can add more WebLLM model IDs here later -->
    </select>
    <button id="btnLoad">Load model</button>
    <small class="mono" id="modelState">idle</small>
  </div>

  <div class="progress"><div class="bar" id="bar"></div></div>
  <small id="barText" class="mono"></small>

  <p style="margin:16px 0 6px">Prompt</p>
  <textarea id="prompt">Generate 5 multiple-choice questions about the water cycle. Number them 1..5 and include options A–D on each line.</textarea>

  <div class="row" style="margin:10px 0 16px">
    <button id="btnGen" disabled>Generate</button>
    <label><input type="checkbox" id="stream" checked/> stream output</label>
  </div>

  <p style="margin:6px 0">Output</p>
  <div class="out" id="out"></div>

  <!-- WebLLM runtime -->
  <script src="https://unpkg.com/@mlc-ai/web-llm/dist/web-llm.min.js"></script>
  <script>
    const W = window.webllm;
    let engine = null;

    const $ = id => document.getElementById(id);
    function setBar(p, text){
      $('bar').style.width = Math.max(0, Math.min(100, p)) + '%';
      $('barText').textContent = text || '';
    }

    $('btnLoad').onclick = async () => {
      if (engine) return;
      $('btnLoad').disabled = true;
      $('modelState').textContent = 'loading…';
      const modelId = $('model').value;

      try{
        engine = await W.CreateMLCEngine(modelId, {
          init_progress_callback: (p) => {
            const pct = Math.round((p.progress || 0) * 100);
            setBar(pct, p.text || 'initializing…');
          },
          log_level: "warn",
          // use_web_worker: true,         // optional: keeps UI more responsive
          // gpu_preferred_textures: ["float16"], // optional: modern GPUs
        });
        $('modelState').textContent = 'ready';
        $('btnGen').disabled = false;
        setBar(100, 'ready');
      }catch(err){
        $('modelState').textContent = 'error';
        setBar(0, 'failed to load model');
        alert('Failed to load model:\n' + (err?.message || err));
        $('btnLoad').disabled = false;
      }
    };

    $('btnGen').onclick = async () => {
      if(!engine) return;
      const prompt = $('prompt').value.trim();
      const stream = $('stream').checked;
      $('out').textContent = '';
      $('btnGen').disabled = true;

      const messages = [
        { role: "system", content: "You generate exam items only, following instructions exactly." },
        { role: "user", content: prompt }
      ];

      if (stream) {
        // Streaming tokens
        const chunks = await engine.chat.completions.create({
          stream: true,
          messages,
          temperature: 0.7,
          max_tokens: 800
        });
        for await (const part of chunks){
          const delta = part?.choices?.[0]?.delta?.content || '';
          if (delta) $('out').textContent += delta;
        }
      } else {
        // Non-streaming
        const res = await engine.chat.completions.create({
          messages,
          temperature: 0.7,
          max_tokens: 800
        });
        $('out').textContent = res?.choices?.[0]?.message?.content || '';
      }

      $('btnGen').disabled = false;
    };
  </script>
</body>
</html>
